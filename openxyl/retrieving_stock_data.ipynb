{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "retrieving_stock_data.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Workflow**:\n",
        "1. Get the data sheet and checklist sheet (in xlsx format) that I've uploaded on Google Drive. Since I'm working on Google Colab, mount my drive's contents.\n",
        "2. Get the stocks name and their respective number of rows which correspond to number of rows. (Don't rely on max_row since empty cells are counted too)\n",
        "3. Extact the table of 22 stocks into 22 seperated file.\n",
        "4. Convert all files into csv files.\n",
        "5. Zip all files\n",
        "\n",
        "**Challenges**:\n",
        "1. Huge amount of data. Inefficient to store on own device or Google drive.\n",
        "2. Impractical to share all the file manually (cloud storage needed)"
      ],
      "metadata": {
        "id": "re26sRG6EFS7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive \n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxHMg-Wqx9Yl",
        "outputId": "a5fb98ea-c934-49d2-b9ab-9cb13ef6831d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openpyxl\n",
        "from openpyxl import Workbook\n",
        "\n",
        "wb = openpyxl.load_workbook(\"/content/drive/MyDrive/Capital Dynamics - Dataset.xlsx\")\n",
        "sheet_data = wb.get_sheet_by_name(\"Data Set\")\n",
        "sheet_checklist = wb.get_sheet_by_name(\"Checklist\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5fM3HG6x9dj",
        "outputId": "d2e28377-9594-436d-c9be-ae855bafc245"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated function get_sheet_by_name (Use wb[sheetname]).\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated function get_sheet_by_name (Use wb[sheetname]).\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# total number of rows\n",
        "print(\"# Rows:\",sheet_data.max_row)\n",
        "\n",
        "# total number of columns\n",
        "print(\"# Columns:\", sheet_data.max_column)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwrM2T9yx9hE",
        "outputId": "98d572dc-49ed-422a-a34b-2ea89b3298fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Rows: 9100\n",
            "# Columns: 153\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# all columns headers (each of them seperated by 7 columns)\n",
        "stocks_name = []\n",
        "for i in range (1, sheet_data.max_column +1, 7):\n",
        "    cell = sheet_data.cell(row = 1, column = i)\n",
        "    if (cell.value):  # in case we include empty cell\n",
        "      stocks_name.append(cell.value)  # value at cell(1, i)\n",
        "\n",
        "print('Stocks: ', stocks_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1afr_30Ax9lJ",
        "outputId": "9ea0198c-b327-40df-93ec-2a16d693940c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stocks:  ['AHEALTH', 'APM', 'BIOHLDG', 'BSTEAD', 'CAPITALA', 'EUPE', 'HPMT', 'ICAP', 'KGB', 'KRONO', 'LUXCHEM', 'MKH', 'OCK', 'OCNCASH', 'PADINI', 'PARKSON', 'SALUTE', 'SAM', 'SURIA', 'TONGHER', 'UTDPLT', 'WELLCAL']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extract number of rows for each stock from Checklist sheet\n",
        "stocks_days = {}\n",
        "\n",
        "for r in range(4, 26):  # we know the contents of sheet :)\n",
        "  if (sheet_checklist.cell(row=r, column = 2)): # make sure it's not empty cell\n",
        "    stocks_days[sheet_checklist.cell(row=r, column = 2).value] = sheet_checklist.cell(row=r, column = 4).value\n",
        "\n",
        "for stock, days in stocks_days.items():\n",
        "  print(stock,\"has\",days,\"rows.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Fqb2Kkcx9sk",
        "outputId": "e9f2aba7-aaa7-4950-cde9-bb13e2a6eb04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AHEALTH has 4475 rows.\n",
            "APM has 5152 rows.\n",
            "BIOHLDG has 1746 rows.\n",
            "BSTEAD has 9095 rows.\n",
            "CAPITALA has 4293 rows.\n",
            "EUPE has 5328 rows.\n",
            "HPMT has 725 rows.\n",
            "ICAP has 3874 rows.\n",
            "KGB has 2670 rows.\n",
            "KRONO has 1826 rows.\n",
            "LUXCHEM has 3308 rows.\n",
            "MKH has 6136 rows.\n",
            "OCK has 2413 rows.\n",
            "OCNCASH has 3234 rows.\n",
            "PADINI has 5060 rows.\n",
            "PARKSON has 3592 rows.\n",
            "SALUTE has 1475 rows.\n",
            "SAM has 5705 rows.\n",
            "SURIA has 6225 rows.\n",
            "TONGHER has 5293 rows.\n",
            "UTDPLT has 7889 rows.\n",
            "WELLCAL has 3761 rows.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create new Google Drive folder\n",
        "import os\n",
        "path = \"drive/MyDrive/hackathon_data\"\n",
        "os.mkdir(path)"
      ],
      "metadata": {
        "id": "RBOn-Av2OD3U"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# formatting datetime\n",
        "# we'll format the cell when copying the contents\n",
        "from openpyxl.styles import NamedStyle\n",
        "\n",
        "date_style = NamedStyle(name=\"formatted_datetime\",\n",
        "                        number_format = \"DD/MM/YYYY HH:MM:MM\")"
      ],
      "metadata": {
        "id": "ksvd_SzKDoyA"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wb1 = openpyxl.load_workbook(\"/content/drive/MyDrive/Capital Dynamics - Dataset.xlsx\")\n",
        "ws1 = wb1.active\n",
        "\n",
        "def create_copy_into_new_file(file_name, min_r, max_r, min_c, max_c):\n",
        "  # create new file\n",
        "  new_wb = Workbook()\n",
        "  new_file_name = file_name + \".xlsx\"\n",
        "  new_wb.save(\"/content/drive/MyDrive/hackathon_data/\"+new_file_name)\n",
        "\n",
        "  # copy contents into new file accordingly to stock\n",
        "  wb2 = openpyxl.load_workbook(\"/content/drive/MyDrive/hackathon_data/\"+new_file_name)\n",
        "  wb2.add_named_style(date_style)\n",
        "  ws2 = wb2.active\n",
        "  for row in ws1.iter_rows(min_row = min_r, max_row = max_r, min_col= min_c, max_col=max_c ):\n",
        "    ws2.append((cell.value for cell in row))\n",
        "  \n",
        "  # save the modified file\n",
        "  wb2.save(\"/content/drive/MyDrive/hackathon_data/\"+new_file_name)\n",
        "\n",
        "# start and end column number for a stock\n",
        "start_col = 1\n",
        "end_col = 6\n",
        "\n",
        "for name, days in stocks_days.items():\n",
        "  create_copy_into_new_file(name, 2, days+2, start_col, end_col)\n",
        "  start_col = start_col + 7\n",
        "  end_col = end_col + 7"
      ],
      "metadata": {
        "id": "kKnSOiX6pJ4y"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert to csv files using pandas library\n",
        "# ####### date in excel file look OK in csv file\n",
        "import pandas as pd\n",
        "\n",
        "def excel_to_csv():\n",
        "  for file in stocks_name:\n",
        "    file_name = file + \".xlsx\"\n",
        "    read_excel_file = pd.read_excel(\"/content/drive/MyDrive/hackathon_data/\"+file_name)\n",
        "    new_file_name = file + \".csv\"\n",
        "    read_excel_file.to_csv((\"/content/drive/MyDrive/hackathon_data/\"+new_file_name), index = None, header = True)\n",
        "excel_to_csv()"
      ],
      "metadata": {
        "id": "nzvDnD_Cy1e7"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# delete xlsx files using Linux command since Google Colab run on Ubuntu\n",
        "!ls\n",
        "\n",
        "# delete all excel files in the specified path\n",
        "!rm drive/MyDrive/hackathon_data/*xlsx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Cf4M5ixN9zK",
        "outputId": "0f524411-02df-41de-bec8-b28a1db8a6aa"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# zip the files and download the zipped file\n",
        "!zip -r hackathon_data.zip /content/drive/MyDrive/hackathon_data\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"/content/hackathon_data.zip\")"
      ],
      "metadata": {
        "id": "JSRfeh4AyqLp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "effade3a-5746-4219-82f2-d83ba00ff4c6"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "updating: content/drive/MyDrive/hackathon_data/ (stored 0%)\n",
            "updating: content/drive/MyDrive/hackathon_data/.ipynb_checkpoints/ (stored 0%)\n",
            "updating: content/drive/MyDrive/hackathon_data/AHEALTH.csv (deflated 79%)\n",
            "updating: content/drive/MyDrive/hackathon_data/APM.csv (deflated 78%)\n",
            "updating: content/drive/MyDrive/hackathon_data/BIOHLDG.csv (deflated 79%)\n",
            "updating: content/drive/MyDrive/hackathon_data/BSTEAD.csv (deflated 77%)\n",
            "updating: content/drive/MyDrive/hackathon_data/CAPITALA.csv (deflated 74%)\n",
            "updating: content/drive/MyDrive/hackathon_data/EUPE.csv (deflated 78%)\n",
            "updating: content/drive/MyDrive/hackathon_data/HPMT.csv (deflated 77%)\n",
            "updating: content/drive/MyDrive/hackathon_data/ICAP.csv (deflated 81%)\n",
            "updating: content/drive/MyDrive/hackathon_data/KGB.csv (deflated 77%)\n",
            "updating: content/drive/MyDrive/hackathon_data/KRONO.csv (deflated 75%)\n",
            "updating: content/drive/MyDrive/hackathon_data/LUXCHEM.csv (deflated 78%)\n",
            "updating: content/drive/MyDrive/hackathon_data/MKH.csv (deflated 76%)\n",
            "updating: content/drive/MyDrive/hackathon_data/OCK.csv (deflated 77%)\n",
            "updating: content/drive/MyDrive/hackathon_data/OCNCASH.csv (deflated 79%)\n",
            "updating: content/drive/MyDrive/hackathon_data/PADINI.csv (deflated 76%)\n",
            "updating: content/drive/MyDrive/hackathon_data/PARKSON.csv (deflated 74%)\n",
            "updating: content/drive/MyDrive/hackathon_data/SALUTE.csv (deflated 74%)\n",
            "updating: content/drive/MyDrive/hackathon_data/SAM.csv (deflated 76%)\n",
            "updating: content/drive/MyDrive/hackathon_data/SURIA.csv (deflated 77%)\n",
            "updating: content/drive/MyDrive/hackathon_data/TONGHER.csv (deflated 77%)\n",
            "updating: content/drive/MyDrive/hackathon_data/UTDPLT.csv (deflated 80%)\n",
            "updating: content/drive/MyDrive/hackathon_data/WELLCAL.csv (deflated 77%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6c1f051a-2795-42dd-9745-2599a055fffb\", \"hackathon_data.zip\", 921762)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}